{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data and Selecting the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train = pd.read_csv('loan_data_inputs_train.csv', index_col = 0)\n",
    "loan_data_targets_train = pd.read_csv('loan_data_targets_train.csv', index_col = 0)\n",
    "loan_data_inputs_test = pd.read_csv('loan_data_inputs_test.csv', index_col = 0)\n",
    "loan_data_targets_test = pd.read_csv('loan_data_targets_test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>...</th>\n",
       "      <th>dti:21.7-22.4</th>\n",
       "      <th>dti:22.4-35</th>\n",
       "      <th>dti:&gt;35</th>\n",
       "      <th>mths_since_last_record:Missing</th>\n",
       "      <th>mths_since_last_record:0-2</th>\n",
       "      <th>mths_since_last_record:3-20</th>\n",
       "      <th>mths_since_last_record:21-31</th>\n",
       "      <th>mths_since_last_record:32-80</th>\n",
       "      <th>mths_since_last_record:81-86</th>\n",
       "      <th>mths_since_last_record:&gt;86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427211</th>\n",
       "      <td>427211</td>\n",
       "      <td>12796369</td>\n",
       "      <td>14818505</td>\n",
       "      <td>24000</td>\n",
       "      <td>24000</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>8.90</td>\n",
       "      <td>762.08</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206088</th>\n",
       "      <td>206088</td>\n",
       "      <td>1439740</td>\n",
       "      <td>1691948</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>14.33</td>\n",
       "      <td>343.39</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136020</th>\n",
       "      <td>136020</td>\n",
       "      <td>5214749</td>\n",
       "      <td>6556909</td>\n",
       "      <td>20425</td>\n",
       "      <td>20425</td>\n",
       "      <td>20425.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>8.90</td>\n",
       "      <td>648.56</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412305</th>\n",
       "      <td>412305</td>\n",
       "      <td>13827698</td>\n",
       "      <td>15890016</td>\n",
       "      <td>17200</td>\n",
       "      <td>17200</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>16.59</td>\n",
       "      <td>609.73</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36159</th>\n",
       "      <td>36159</td>\n",
       "      <td>422455</td>\n",
       "      <td>496525</td>\n",
       "      <td>8400</td>\n",
       "      <td>8400</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>12.84</td>\n",
       "      <td>282.40</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        id  member_id  loan_amnt  funded_amnt  \\\n",
       "427211      427211  12796369   14818505      24000        24000   \n",
       "206088      206088   1439740    1691948      10000        10000   \n",
       "136020      136020   5214749    6556909      20425        20425   \n",
       "412305      412305  13827698   15890016      17200        17200   \n",
       "36159        36159    422455     496525       8400         8400   \n",
       "\n",
       "        funded_amnt_inv        term  int_rate  installment grade  ...  \\\n",
       "427211          24000.0   36 months      8.90       762.08     A  ...   \n",
       "206088          10000.0   36 months     14.33       343.39     C  ...   \n",
       "136020          20425.0   36 months      8.90       648.56     A  ...   \n",
       "412305          17200.0   36 months     16.59       609.73     D  ...   \n",
       "36159            7450.0   36 months     12.84       282.40     C  ...   \n",
       "\n",
       "       dti:21.7-22.4 dti:22.4-35 dti:>35 mths_since_last_record:Missing  \\\n",
       "427211             1           0       0                              1   \n",
       "206088             0           0       0                              1   \n",
       "136020             0           0       0                              1   \n",
       "412305             0           0       0                              1   \n",
       "36159              0           1       0                              1   \n",
       "\n",
       "        mths_since_last_record:0-2 mths_since_last_record:3-20  \\\n",
       "427211                           0                           0   \n",
       "206088                           0                           0   \n",
       "136020                           0                           0   \n",
       "412305                           0                           0   \n",
       "36159                            0                           0   \n",
       "\n",
       "       mths_since_last_record:21-31 mths_since_last_record:32-80  \\\n",
       "427211                            0                            0   \n",
       "206088                            0                            0   \n",
       "136020                            0                            0   \n",
       "412305                            0                            0   \n",
       "36159                             0                            0   \n",
       "\n",
       "       mths_since_last_record:81-86 mths_since_last_record:>86  \n",
       "427211                            0                          0  \n",
       "206088                            0                          0  \n",
       "136020                            0                          0  \n",
       "412305                            0                          0  \n",
       "36159                             0                          0  \n",
       "\n",
       "[5 rows x 324 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_inputs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427211</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206088</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136020</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36159</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        good_bad\n",
       "427211         1\n",
       "206088         1\n",
       "136020         1\n",
       "412305         0\n",
       "36159          0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_targets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373028, 324)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373028, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_targets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93257, 324)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93257, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_targets_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we select a limited set of input variables in a new dataframe.\n",
    "inputs_train_with_ref_cat = loan_data_inputs_train.loc[: , ['grade:A',\n",
    "'grade:B',\n",
    "'grade:C',\n",
    "'grade:D',\n",
    "'grade:E',\n",
    "'grade:F',\n",
    "'grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'home_ownership:OWN',\n",
    "'home_ownership:MORTGAGE',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'addr_state:NM_VA',\n",
    "'addr_state:NY',\n",
    "'addr_state:OK_TN_MO_LA_MD_NC',\n",
    "'addr_state:CA',\n",
    "'addr_state:UT_KY_AZ_NJ',\n",
    "'addr_state:AR_MI_PA_OH_MN',\n",
    "'addr_state:RI_MA_DE_SD_IN',\n",
    "'addr_state:GA_WA_OR',\n",
    "'addr_state:WI_MT',\n",
    "'addr_state:TX',\n",
    "'addr_state:IL_CT',\n",
    "'addr_state:KS_SC_CO_VT_AK_MS',\n",
    "'addr_state:WV_NH_WY_DC_ME_ID',\n",
    "'verification_status:Not Verified',\n",
    "'verification_status:Source Verified',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'purpose:credit_card',\n",
    "'purpose:debt_consolidation',\n",
    "'purpose:oth__med__vacation',\n",
    "'purpose:major_purch__car__home_impr',\n",
    "'initial_list_status:f',\n",
    "'initial_list_status:w',\n",
    "'term:36',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'emp_length:1',\n",
    "'emp_length:2-4',\n",
    "'emp_length:5-6',\n",
    "'emp_length:7-9',\n",
    "'emp_length:10',\n",
    "'mths_since_issue_d:<38',\n",
    "'mths_since_issue_d:38-39',\n",
    "'mths_since_issue_d:40-41',\n",
    "'mths_since_issue_d:42-48',\n",
    "'mths_since_issue_d:49-52',\n",
    "'mths_since_issue_d:53-64',\n",
    "'mths_since_issue_d:65-84',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:<9.548',\n",
    "'int_rate:9.548-12.025',\n",
    "'int_rate:12.025-15.74',\n",
    "'int_rate:15.74-20.281',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'mths_since_earliest_cr_line:141-164',\n",
    "'mths_since_earliest_cr_line:165-247',\n",
    "'mths_since_earliest_cr_line:248-270',\n",
    "'mths_since_earliest_cr_line:271-352',\n",
    "'mths_since_earliest_cr_line:>352',\n",
    "'delinq_2yrs:0',\n",
    "'delinq_2yrs:1-3',\n",
    "'delinq_2yrs:>=4',\n",
    "'inq_last_6mths:0',\n",
    "'inq_last_6mths:1-2',\n",
    "'inq_last_6mths:3-6',\n",
    "'inq_last_6mths:>6',\n",
    "'open_acc:0',\n",
    "'open_acc:1-3',\n",
    "'open_acc:4-12',\n",
    "'open_acc:13-17',\n",
    "'open_acc:18-22',\n",
    "'open_acc:23-25',\n",
    "'open_acc:26-30',\n",
    "'open_acc:>=31',\n",
    "'pub_rec:0-2',\n",
    "'pub_rec:3-4',\n",
    "'pub_rec:>=5',\n",
    "'total_acc:<=27',\n",
    "'total_acc:28-51',\n",
    "'total_acc:>=52',\n",
    "'acc_now_delinq:0',\n",
    "'acc_now_delinq:>=1',\n",
    "'total_rev_hi_lim:<=5K',\n",
    "'total_rev_hi_lim:5K-10K',\n",
    "'total_rev_hi_lim:10K-20K',\n",
    "'total_rev_hi_lim:20K-30K',\n",
    "'total_rev_hi_lim:30K-40K',\n",
    "'total_rev_hi_lim:40K-55K',\n",
    "'total_rev_hi_lim:55K-95K',\n",
    "'total_rev_hi_lim:>95K',\n",
    "'annual_inc:<20K',\n",
    "'annual_inc:20K-30K',\n",
    "'annual_inc:30K-40K',\n",
    "'annual_inc:40K-50K',\n",
    "'annual_inc:50K-60K',\n",
    "'annual_inc:60K-70K',\n",
    "'annual_inc:70K-80K',\n",
    "'annual_inc:80K-90K',\n",
    "'annual_inc:90K-100K',\n",
    "'annual_inc:100K-120K',\n",
    "'annual_inc:120K-140K',\n",
    "'annual_inc:>140K',\n",
    "'dti:<=1.4',\n",
    "'dti:1.4-3.5',\n",
    "'dti:3.5-7.7',\n",
    "'dti:7.7-10.5',\n",
    "'dti:10.5-16.1',\n",
    "'dti:16.1-20.3',\n",
    "'dti:20.3-21.7',\n",
    "'dti:21.7-22.4',\n",
    "'dti:22.4-35',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:Missing',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_delinq:4-30',\n",
    "'mths_since_last_delinq:31-56',\n",
    "'mths_since_last_delinq:>=57',\n",
    "'mths_since_last_record:Missing',\n",
    "'mths_since_last_record:0-2',\n",
    "'mths_since_last_record:3-20',\n",
    "'mths_since_last_record:21-31',\n",
    "'mths_since_last_record:32-80',\n",
    "'mths_since_last_record:81-86',\n",
    "'mths_since_last_record:>86',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we store the names of the reference category dummy variables in a list.\n",
    "ref_categories = ['grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'initial_list_status:f',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'delinq_2yrs:>=4',\n",
    "'inq_last_6mths:>6',\n",
    "'open_acc:0',\n",
    "'pub_rec:0-2',\n",
    "'total_acc:<=27',\n",
    "'acc_now_delinq:0',\n",
    "'total_rev_hi_lim:<=5K',\n",
    "'annual_inc:<20K',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_record:0-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade:A</th>\n",
       "      <th>grade:B</th>\n",
       "      <th>grade:C</th>\n",
       "      <th>grade:D</th>\n",
       "      <th>grade:E</th>\n",
       "      <th>grade:F</th>\n",
       "      <th>home_ownership:OWN</th>\n",
       "      <th>home_ownership:MORTGAGE</th>\n",
       "      <th>addr_state:NM_VA</th>\n",
       "      <th>addr_state:NY</th>\n",
       "      <th>...</th>\n",
       "      <th>mths_since_last_delinq:Missing</th>\n",
       "      <th>mths_since_last_delinq:4-30</th>\n",
       "      <th>mths_since_last_delinq:31-56</th>\n",
       "      <th>mths_since_last_delinq:&gt;=57</th>\n",
       "      <th>mths_since_last_record:Missing</th>\n",
       "      <th>mths_since_last_record:3-20</th>\n",
       "      <th>mths_since_last_record:21-31</th>\n",
       "      <th>mths_since_last_record:32-80</th>\n",
       "      <th>mths_since_last_record:81-86</th>\n",
       "      <th>mths_since_last_record:&gt;86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427211</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206088</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136020</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412305</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36159</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        grade:A  grade:B  grade:C  grade:D  grade:E  grade:F  \\\n",
       "427211     True    False    False    False    False    False   \n",
       "206088    False    False     True    False    False    False   \n",
       "136020     True    False    False    False    False    False   \n",
       "412305    False    False    False     True    False    False   \n",
       "36159     False    False     True    False    False    False   \n",
       "\n",
       "        home_ownership:OWN  home_ownership:MORTGAGE  addr_state:NM_VA  \\\n",
       "427211               False                     True                 0   \n",
       "206088               False                     True                 0   \n",
       "136020               False                     True                 0   \n",
       "412305               False                    False                 0   \n",
       "36159                False                     True                 0   \n",
       "\n",
       "        addr_state:NY  ...  mths_since_last_delinq:Missing  \\\n",
       "427211          False  ...                               1   \n",
       "206088          False  ...                               0   \n",
       "136020          False  ...                               0   \n",
       "412305          False  ...                               0   \n",
       "36159           False  ...                               1   \n",
       "\n",
       "        mths_since_last_delinq:4-30  mths_since_last_delinq:31-56  \\\n",
       "427211                            0                             0   \n",
       "206088                            1                             0   \n",
       "136020                            0                             1   \n",
       "412305                            1                             0   \n",
       "36159                             0                             0   \n",
       "\n",
       "        mths_since_last_delinq:>=57  mths_since_last_record:Missing  \\\n",
       "427211                            0                               1   \n",
       "206088                            0                               1   \n",
       "136020                            0                               1   \n",
       "412305                            0                               1   \n",
       "36159                             0                               1   \n",
       "\n",
       "        mths_since_last_record:3-20  mths_since_last_record:21-31  \\\n",
       "427211                            0                             0   \n",
       "206088                            0                             0   \n",
       "136020                            0                             0   \n",
       "412305                            0                             0   \n",
       "36159                             0                             0   \n",
       "\n",
       "        mths_since_last_record:32-80  mths_since_last_record:81-86  \\\n",
       "427211                             0                             0   \n",
       "206088                             0                             0   \n",
       "136020                             0                             0   \n",
       "412305                             0                             0   \n",
       "36159                              0                             0   \n",
       "\n",
       "        mths_since_last_record:>86  \n",
       "427211                           0  \n",
       "206088                           0  \n",
       "136020                           0  \n",
       "412305                           0  \n",
       "36159                            0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train = inputs_train_with_ref_cat.drop(ref_categories, axis = 1)\n",
    "# From the dataframe with input variables, we drop the variables with variable names in the list with reference categories. \n",
    "inputs_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD Model Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()\n",
    "# We create an instance of an object from the 'LogisticRegression' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "# Sets the pandas dataframe options to display all columns/ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kumar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(inputs_train, loan_data_targets_train)\n",
    "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
    "# with inputs (independent variables) contained in the first dataframe\n",
    "# and targets (dependent variables) contained in the second dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.30135228])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_\n",
    "# Displays the intercept contain in the estimated (\"fitted\") object from the 'LogisticRegression' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.15878073,  0.90985999,  0.71206818,  0.51795814,  0.33736248,\n",
       "         0.14920211,  0.09216893,  0.1067057 ,  0.03212309,  0.05423655,\n",
       "         0.05518118,  0.0579566 ,  0.07329997,  0.13187248,  0.09589385,\n",
       "         0.18036951,  0.2221349 ,  0.22088182,  0.25836603,  0.31649288,\n",
       "         0.51924685,  0.08695156, -0.00885968,  0.30474912,  0.20078535,\n",
       "         0.21298061,  0.26637264,  0.05454419,  0.07954815,  0.09979285,\n",
       "         0.12398826,  0.08914546,  0.05863969,  0.12226164,  0.9750849 ,\n",
       "         0.79696558,  0.71675803,  0.53069608,  0.37492478,  0.13065185,\n",
       "        -0.07042952,  0.85367971,  0.53544595,  0.28972494,  0.10309042,\n",
       "         0.0332204 ,  0.03340604,  0.08177004,  0.11257727,  0.11193229,\n",
       "         0.05924347,  0.01799063,  0.62181593,  0.47794905,  0.26954739,\n",
       "        -0.00584135, -0.10544352, -0.13189102, -0.1472934 , -0.15600357,\n",
       "        -0.12350547, -0.20635207,  0.1261136 ,  0.17588814, -0.02171649,\n",
       "         0.02061183,  0.21928905,  0.03821478,  0.00845401,  0.00997133,\n",
       "         0.02416917,  0.04945392,  0.07690586,  0.22129861, -0.0614807 ,\n",
       "         0.00624915,  0.10500437,  0.17345502,  0.25142988,  0.32245244,\n",
       "         0.39848586,  0.41820182,  0.49451208,  0.5826294 ,  0.51152484,\n",
       "         0.21066231,  0.33687866,  0.36424624,  0.30502755,  0.22899001,\n",
       "         0.13145621,  0.11990927,  0.08525256,  0.04689782,  0.0812223 ,\n",
       "         0.14799347,  0.16307599,  0.11366092,  0.34104154,  0.44108274,\n",
       "         0.37094899,  0.52971661,  0.20304265,  0.25566921]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_\n",
    "# Displays the coefficients contained in the estimated (\"fitted\") object from the 'LogisticRegression' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = inputs_train.columns.values\n",
    "# Stores the names of the columns of a dataframe in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.301352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grade:A</td>\n",
       "      <td>1.158781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grade:B</td>\n",
       "      <td>0.909860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grade:C</td>\n",
       "      <td>0.712068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grade:D</td>\n",
       "      <td>0.517958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grade:E</td>\n",
       "      <td>0.337362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grade:F</td>\n",
       "      <td>0.149202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>home_ownership:OWN</td>\n",
       "      <td>0.092169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_ownership:MORTGAGE</td>\n",
       "      <td>0.106706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>addr_state:NM_VA</td>\n",
       "      <td>0.032123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>addr_state:NY</td>\n",
       "      <td>0.054237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>addr_state:OK_TN_MO_LA_MD_NC</td>\n",
       "      <td>0.055181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>addr_state:CA</td>\n",
       "      <td>0.057957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>addr_state:UT_KY_AZ_NJ</td>\n",
       "      <td>0.073300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>addr_state:AR_MI_PA_OH_MN</td>\n",
       "      <td>0.131872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>addr_state:RI_MA_DE_SD_IN</td>\n",
       "      <td>0.095894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>addr_state:GA_WA_OR</td>\n",
       "      <td>0.180370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>addr_state:WI_MT</td>\n",
       "      <td>0.222135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>addr_state:TX</td>\n",
       "      <td>0.220882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>addr_state:IL_CT</td>\n",
       "      <td>0.258366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>addr_state:KS_SC_CO_VT_AK_MS</td>\n",
       "      <td>0.316493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>addr_state:WV_NH_WY_DC_ME_ID</td>\n",
       "      <td>0.519247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>verification_status:Not Verified</td>\n",
       "      <td>0.086952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>verification_status:Source Verified</td>\n",
       "      <td>-0.008860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>purpose:credit_card</td>\n",
       "      <td>0.304749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>purpose:debt_consolidation</td>\n",
       "      <td>0.200785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>purpose:oth__med__vacation</td>\n",
       "      <td>0.212981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>purpose:major_purch__car__home_impr</td>\n",
       "      <td>0.266373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>initial_list_status:w</td>\n",
       "      <td>0.054544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>term:36</td>\n",
       "      <td>0.079548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>emp_length:1</td>\n",
       "      <td>0.099793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>emp_length:2-4</td>\n",
       "      <td>0.123988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>emp_length:5-6</td>\n",
       "      <td>0.089145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>emp_length:7-9</td>\n",
       "      <td>0.058640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>emp_length:10</td>\n",
       "      <td>0.122262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mths_since_issue_d:&lt;38</td>\n",
       "      <td>0.975085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mths_since_issue_d:38-39</td>\n",
       "      <td>0.796966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mths_since_issue_d:40-41</td>\n",
       "      <td>0.716758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mths_since_issue_d:42-48</td>\n",
       "      <td>0.530696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mths_since_issue_d:49-52</td>\n",
       "      <td>0.374925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mths_since_issue_d:53-64</td>\n",
       "      <td>0.130652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mths_since_issue_d:65-84</td>\n",
       "      <td>-0.070430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>int_rate:&lt;9.548</td>\n",
       "      <td>0.853680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>int_rate:9.548-12.025</td>\n",
       "      <td>0.535446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>int_rate:12.025-15.74</td>\n",
       "      <td>0.289725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>int_rate:15.74-20.281</td>\n",
       "      <td>0.103090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mths_since_earliest_cr_line:141-164</td>\n",
       "      <td>0.033220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mths_since_earliest_cr_line:165-247</td>\n",
       "      <td>0.033406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mths_since_earliest_cr_line:248-270</td>\n",
       "      <td>0.081770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mths_since_earliest_cr_line:271-352</td>\n",
       "      <td>0.112577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mths_since_earliest_cr_line:&gt;352</td>\n",
       "      <td>0.111932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>delinq_2yrs:0</td>\n",
       "      <td>0.059243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>delinq_2yrs:1-3</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>inq_last_6mths:0</td>\n",
       "      <td>0.621816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>inq_last_6mths:1-2</td>\n",
       "      <td>0.477949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>inq_last_6mths:3-6</td>\n",
       "      <td>0.269547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>open_acc:1-3</td>\n",
       "      <td>-0.005841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>open_acc:4-12</td>\n",
       "      <td>-0.105444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>open_acc:13-17</td>\n",
       "      <td>-0.131891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>open_acc:18-22</td>\n",
       "      <td>-0.147293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>open_acc:23-25</td>\n",
       "      <td>-0.156004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>open_acc:26-30</td>\n",
       "      <td>-0.123505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>open_acc:&gt;=31</td>\n",
       "      <td>-0.206352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>pub_rec:3-4</td>\n",
       "      <td>0.126114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>pub_rec:&gt;=5</td>\n",
       "      <td>0.175888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>total_acc:28-51</td>\n",
       "      <td>-0.021716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>total_acc:&gt;=52</td>\n",
       "      <td>0.020612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>acc_now_delinq:&gt;=1</td>\n",
       "      <td>0.219289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>total_rev_hi_lim:5K-10K</td>\n",
       "      <td>0.038215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>total_rev_hi_lim:10K-20K</td>\n",
       "      <td>0.008454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>total_rev_hi_lim:20K-30K</td>\n",
       "      <td>0.009971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>total_rev_hi_lim:30K-40K</td>\n",
       "      <td>0.024169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>total_rev_hi_lim:40K-55K</td>\n",
       "      <td>0.049454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>total_rev_hi_lim:55K-95K</td>\n",
       "      <td>0.076906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>total_rev_hi_lim:&gt;95K</td>\n",
       "      <td>0.221299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>annual_inc:20K-30K</td>\n",
       "      <td>-0.061481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>annual_inc:30K-40K</td>\n",
       "      <td>0.006249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>annual_inc:40K-50K</td>\n",
       "      <td>0.105004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>annual_inc:50K-60K</td>\n",
       "      <td>0.173455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>annual_inc:60K-70K</td>\n",
       "      <td>0.251430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>annual_inc:70K-80K</td>\n",
       "      <td>0.322452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>annual_inc:80K-90K</td>\n",
       "      <td>0.398486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>annual_inc:90K-100K</td>\n",
       "      <td>0.418202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>annual_inc:100K-120K</td>\n",
       "      <td>0.494512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>annual_inc:120K-140K</td>\n",
       "      <td>0.582629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>annual_inc:&gt;140K</td>\n",
       "      <td>0.511525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>dti:&lt;=1.4</td>\n",
       "      <td>0.210662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>dti:1.4-3.5</td>\n",
       "      <td>0.336879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>dti:3.5-7.7</td>\n",
       "      <td>0.364246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>dti:7.7-10.5</td>\n",
       "      <td>0.305028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>dti:10.5-16.1</td>\n",
       "      <td>0.228990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>dti:16.1-20.3</td>\n",
       "      <td>0.131456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>dti:20.3-21.7</td>\n",
       "      <td>0.119909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>dti:21.7-22.4</td>\n",
       "      <td>0.085253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>dti:22.4-35</td>\n",
       "      <td>0.046898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mths_since_last_delinq:Missing</td>\n",
       "      <td>0.081222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mths_since_last_delinq:4-30</td>\n",
       "      <td>0.147993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mths_since_last_delinq:31-56</td>\n",
       "      <td>0.163076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mths_since_last_delinq:&gt;=57</td>\n",
       "      <td>0.113661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mths_since_last_record:Missing</td>\n",
       "      <td>0.341042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>mths_since_last_record:3-20</td>\n",
       "      <td>0.441083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>mths_since_last_record:21-31</td>\n",
       "      <td>0.370949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>mths_since_last_record:32-80</td>\n",
       "      <td>0.529717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>mths_since_last_record:81-86</td>\n",
       "      <td>0.203043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>mths_since_last_record:&gt;86</td>\n",
       "      <td>0.255669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Feature name  Coefficients\n",
       "0                              Intercept     -1.301352\n",
       "1                                grade:A      1.158781\n",
       "2                                grade:B      0.909860\n",
       "3                                grade:C      0.712068\n",
       "4                                grade:D      0.517958\n",
       "5                                grade:E      0.337362\n",
       "6                                grade:F      0.149202\n",
       "7                     home_ownership:OWN      0.092169\n",
       "8                home_ownership:MORTGAGE      0.106706\n",
       "9                       addr_state:NM_VA      0.032123\n",
       "10                         addr_state:NY      0.054237\n",
       "11          addr_state:OK_TN_MO_LA_MD_NC      0.055181\n",
       "12                         addr_state:CA      0.057957\n",
       "13                addr_state:UT_KY_AZ_NJ      0.073300\n",
       "14             addr_state:AR_MI_PA_OH_MN      0.131872\n",
       "15             addr_state:RI_MA_DE_SD_IN      0.095894\n",
       "16                   addr_state:GA_WA_OR      0.180370\n",
       "17                      addr_state:WI_MT      0.222135\n",
       "18                         addr_state:TX      0.220882\n",
       "19                      addr_state:IL_CT      0.258366\n",
       "20          addr_state:KS_SC_CO_VT_AK_MS      0.316493\n",
       "21          addr_state:WV_NH_WY_DC_ME_ID      0.519247\n",
       "22      verification_status:Not Verified      0.086952\n",
       "23   verification_status:Source Verified     -0.008860\n",
       "24                   purpose:credit_card      0.304749\n",
       "25            purpose:debt_consolidation      0.200785\n",
       "26            purpose:oth__med__vacation      0.212981\n",
       "27   purpose:major_purch__car__home_impr      0.266373\n",
       "28                 initial_list_status:w      0.054544\n",
       "29                               term:36      0.079548\n",
       "30                          emp_length:1      0.099793\n",
       "31                        emp_length:2-4      0.123988\n",
       "32                        emp_length:5-6      0.089145\n",
       "33                        emp_length:7-9      0.058640\n",
       "34                         emp_length:10      0.122262\n",
       "35                mths_since_issue_d:<38      0.975085\n",
       "36              mths_since_issue_d:38-39      0.796966\n",
       "37              mths_since_issue_d:40-41      0.716758\n",
       "38              mths_since_issue_d:42-48      0.530696\n",
       "39              mths_since_issue_d:49-52      0.374925\n",
       "40              mths_since_issue_d:53-64      0.130652\n",
       "41              mths_since_issue_d:65-84     -0.070430\n",
       "42                       int_rate:<9.548      0.853680\n",
       "43                 int_rate:9.548-12.025      0.535446\n",
       "44                 int_rate:12.025-15.74      0.289725\n",
       "45                 int_rate:15.74-20.281      0.103090\n",
       "46   mths_since_earliest_cr_line:141-164      0.033220\n",
       "47   mths_since_earliest_cr_line:165-247      0.033406\n",
       "48   mths_since_earliest_cr_line:248-270      0.081770\n",
       "49   mths_since_earliest_cr_line:271-352      0.112577\n",
       "50      mths_since_earliest_cr_line:>352      0.111932\n",
       "51                         delinq_2yrs:0      0.059243\n",
       "52                       delinq_2yrs:1-3      0.017991\n",
       "53                      inq_last_6mths:0      0.621816\n",
       "54                    inq_last_6mths:1-2      0.477949\n",
       "55                    inq_last_6mths:3-6      0.269547\n",
       "56                          open_acc:1-3     -0.005841\n",
       "57                         open_acc:4-12     -0.105444\n",
       "58                        open_acc:13-17     -0.131891\n",
       "59                        open_acc:18-22     -0.147293\n",
       "60                        open_acc:23-25     -0.156004\n",
       "61                        open_acc:26-30     -0.123505\n",
       "62                         open_acc:>=31     -0.206352\n",
       "63                           pub_rec:3-4      0.126114\n",
       "64                           pub_rec:>=5      0.175888\n",
       "65                       total_acc:28-51     -0.021716\n",
       "66                        total_acc:>=52      0.020612\n",
       "67                    acc_now_delinq:>=1      0.219289\n",
       "68               total_rev_hi_lim:5K-10K      0.038215\n",
       "69              total_rev_hi_lim:10K-20K      0.008454\n",
       "70              total_rev_hi_lim:20K-30K      0.009971\n",
       "71              total_rev_hi_lim:30K-40K      0.024169\n",
       "72              total_rev_hi_lim:40K-55K      0.049454\n",
       "73              total_rev_hi_lim:55K-95K      0.076906\n",
       "74                 total_rev_hi_lim:>95K      0.221299\n",
       "75                    annual_inc:20K-30K     -0.061481\n",
       "76                    annual_inc:30K-40K      0.006249\n",
       "77                    annual_inc:40K-50K      0.105004\n",
       "78                    annual_inc:50K-60K      0.173455\n",
       "79                    annual_inc:60K-70K      0.251430\n",
       "80                    annual_inc:70K-80K      0.322452\n",
       "81                    annual_inc:80K-90K      0.398486\n",
       "82                   annual_inc:90K-100K      0.418202\n",
       "83                  annual_inc:100K-120K      0.494512\n",
       "84                  annual_inc:120K-140K      0.582629\n",
       "85                      annual_inc:>140K      0.511525\n",
       "86                             dti:<=1.4      0.210662\n",
       "87                           dti:1.4-3.5      0.336879\n",
       "88                           dti:3.5-7.7      0.364246\n",
       "89                          dti:7.7-10.5      0.305028\n",
       "90                         dti:10.5-16.1      0.228990\n",
       "91                         dti:16.1-20.3      0.131456\n",
       "92                         dti:20.3-21.7      0.119909\n",
       "93                         dti:21.7-22.4      0.085253\n",
       "94                           dti:22.4-35      0.046898\n",
       "95        mths_since_last_delinq:Missing      0.081222\n",
       "96           mths_since_last_delinq:4-30      0.147993\n",
       "97          mths_since_last_delinq:31-56      0.163076\n",
       "98           mths_since_last_delinq:>=57      0.113661\n",
       "99        mths_since_last_record:Missing      0.341042\n",
       "100          mths_since_last_record:3-20      0.441083\n",
       "101         mths_since_last_record:21-31      0.370949\n",
       "102         mths_since_last_record:32-80      0.529717\n",
       "103         mths_since_last_record:81-86      0.203043\n",
       "104           mths_since_last_record:>86      0.255669"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
    "summary_table['Coefficients'] = np.transpose(reg.coef_)\n",
    "# Creates a new column in the dataframe, called 'Coefficients',\n",
    "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
    "summary_table.index = summary_table.index + 1\n",
    "# Increases the index of every row of the dataframe with 1.\n",
    "summary_table.loc[0] = ['Intercept', reg.intercept_[0]]\n",
    "# Assigns values of the row with index 0 of the dataframe.\n",
    "summary_table = summary_table.sort_index()\n",
    "# Sorts the dataframe by index.\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Logistic Regression Model with P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P values for sklearn logistic regression.\n",
    "\n",
    "# Class to display p-values for logistic regression in sklearn.\n",
    "\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as stat\n",
    "\n",
    "class LogisticRegression_with_p_values:\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):#,**kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args,**kwargs)#,**args)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.model.fit(X,y)\n",
    "        \n",
    "        #### Get p-values for the fitted model ####\n",
    "        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X / denom).T,X) ## Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij) ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.model.coef_[0] / sigma_estimates # z-score for eaach model coefficient\n",
    "        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores] ### two tailed test for p-values\n",
    "        \n",
    "        self.coef_ = self.model.coef_\n",
    "        self.intercept_ = self.model.intercept_\n",
    "        #self.z_scores = z_scores\n",
    "        self.p_values = p_values\n",
    "        #self.sigma_estimates = sigma_estimates\n",
    "        #self.F_ij = F_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import scipy.stats as stat\n",
    "\n",
    "class LogisticRegression_with_p_values:\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args,**kwargs)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.model.fit(X,y)\n",
    "        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X / denom).T,X)\n",
    "        Cramer_Rao = np.linalg.inv(F_ij)\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.model.coef_[0] / sigma_estimates\n",
    "        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores]\n",
    "        self.coef_ = self.model.coef_\n",
    "        self.intercept_ = self.model.intercept_\n",
    "        self.p_values = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression_with_p_values()\n",
    "# We create an instance of an object from the newly created 'LogisticRegression_with_p_values()' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kumar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'inv' input from dtype('O') to dtype('float64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(inputs_train, loan_data_targets_train)\n",
      "Cell \u001b[1;32mIn[53], line 14\u001b[0m, in \u001b[0;36mLogisticRegression_with_p_values.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m denom \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(denom,(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     13\u001b[0m F_ij \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot((X \u001b[38;5;241m/\u001b[39m denom)\u001b[38;5;241m.\u001b[39mT,X)\n\u001b[1;32m---> 14\u001b[0m Cramer_Rao \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(F_ij)\n\u001b[0;32m     15\u001b[0m sigma_estimates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mdiagonal(Cramer_Rao))\n\u001b[0;32m     16\u001b[0m z_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m sigma_estimates\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:538\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    536\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    537\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 538\u001b[0m ainv \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39minv(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'inv' input from dtype('O') to dtype('float64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "reg.fit(inputs_train, loan_data_targets_train)\n",
    "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
    "# with inputs (independent variables) contained in the first dataframe\n",
    "# and targets (dependent variables) contained in the second dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above.\n",
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table['Coefficients'] = np.transpose(reg.coef_)\n",
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg.intercept_[0]]\n",
    "summary_table = summary_table.sort_index()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list.\n",
    "p_values = reg.p_values\n",
    "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the intercept for completeness.\n",
    "p_values = np.append(np.nan, np.array(p_values))\n",
    "# We add the value 'NaN' in the beginning of the variable with p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table['p_values'] = p_values\n",
    "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to remove some features, the coefficients for all or almost all of the dummy variables for which,\n",
    "# are not tatistically significant.\n",
    "\n",
    "# We do that by specifying another list of dummy variables as reference categories, and a list of variables to remove.\n",
    "# Then, we are going to drop the two datasets from the original list of dummy variables.\n",
    "\n",
    "# Variables\n",
    "inputs_train_with_ref_cat = loan_data_inputs_train.loc[: , ['grade:A',\n",
    "'grade:B',\n",
    "'grade:C',\n",
    "'grade:D',\n",
    "'grade:E',\n",
    "'grade:F',\n",
    "'grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'home_ownership:OWN',\n",
    "'home_ownership:MORTGAGE',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'addr_state:NM_VA',\n",
    "'addr_state:NY',\n",
    "'addr_state:OK_TN_MO_LA_MD_NC',\n",
    "'addr_state:CA',\n",
    "'addr_state:UT_KY_AZ_NJ',\n",
    "'addr_state:AR_MI_PA_OH_MN',\n",
    "'addr_state:RI_MA_DE_SD_IN',\n",
    "'addr_state:GA_WA_OR',\n",
    "'addr_state:WI_MT',\n",
    "'addr_state:TX',\n",
    "'addr_state:IL_CT',\n",
    "'addr_state:KS_SC_CO_VT_AK_MS',\n",
    "'addr_state:WV_NH_WY_DC_ME_ID',\n",
    "'verification_status:Not Verified',\n",
    "'verification_status:Source Verified',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'purpose:credit_card',\n",
    "'purpose:debt_consolidation',\n",
    "'purpose:oth__med__vacation',\n",
    "'purpose:major_purch__car__home_impr',\n",
    "'initial_list_status:f',\n",
    "'initial_list_status:w',\n",
    "'term:36',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'emp_length:1',\n",
    "'emp_length:2-4',\n",
    "'emp_length:5-6',\n",
    "'emp_length:7-9',\n",
    "'emp_length:10',\n",
    "'mths_since_issue_d:<38',\n",
    "'mths_since_issue_d:38-39',\n",
    "'mths_since_issue_d:40-41',\n",
    "'mths_since_issue_d:42-48',\n",
    "'mths_since_issue_d:49-52',\n",
    "'mths_since_issue_d:53-64',\n",
    "'mths_since_issue_d:65-84',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:<9.548',\n",
    "'int_rate:9.548-12.025',\n",
    "'int_rate:12.025-15.74',\n",
    "'int_rate:15.74-20.281',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'mths_since_earliest_cr_line:141-164',\n",
    "'mths_since_earliest_cr_line:165-247',\n",
    "'mths_since_earliest_cr_line:248-270',\n",
    "'mths_since_earliest_cr_line:271-352',\n",
    "'mths_since_earliest_cr_line:>352',\n",
    "'inq_last_6mths:0',\n",
    "'inq_last_6mths:1-2',\n",
    "'inq_last_6mths:3-6',\n",
    "'inq_last_6mths:>6',\n",
    "'acc_now_delinq:0',\n",
    "'acc_now_delinq:>=1',\n",
    "'annual_inc:<20K',\n",
    "'annual_inc:20K-30K',\n",
    "'annual_inc:30K-40K',\n",
    "'annual_inc:40K-50K',\n",
    "'annual_inc:50K-60K',\n",
    "'annual_inc:60K-70K',\n",
    "'annual_inc:70K-80K',\n",
    "'annual_inc:80K-90K',\n",
    "'annual_inc:90K-100K',\n",
    "'annual_inc:100K-120K',\n",
    "'annual_inc:120K-140K',\n",
    "'annual_inc:>140K',\n",
    "'dti:<=1.4',\n",
    "'dti:1.4-3.5',\n",
    "'dti:3.5-7.7',\n",
    "'dti:7.7-10.5',\n",
    "'dti:10.5-16.1',\n",
    "'dti:16.1-20.3',\n",
    "'dti:20.3-21.7',\n",
    "'dti:21.7-22.4',\n",
    "'dti:22.4-35',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:Missing',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_delinq:4-30',\n",
    "'mths_since_last_delinq:31-56',\n",
    "'mths_since_last_delinq:>=57',\n",
    "'mths_since_last_record:Missing',\n",
    "'mths_since_last_record:0-2',\n",
    "'mths_since_last_record:3-20',\n",
    "'mths_since_last_record:21-31',\n",
    "'mths_since_last_record:32-80',\n",
    "'mths_since_last_record:81-86',\n",
    "'mths_since_last_record:>=86',\n",
    "]]\n",
    "\n",
    "ref_categories = ['grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'initial_list_status:f',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'inq_last_6mths:>6',\n",
    "'acc_now_delinq:0',\n",
    "'annual_inc:<20K',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_record:0-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_train = inputs_train_with_ref_cat.drop(ref_categories, axis = 1)\n",
    "inputs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we run a new model.\n",
    "reg2 = LogisticRegression_with_p_values()\n",
    "reg2.fit(inputs_train, loan_data_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = inputs_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above.\n",
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table['Coefficients'] = np.transpose(reg2.coef_)\n",
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg2.intercept_[0]]\n",
    "summary_table = summary_table.sort_index()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the 'p_values' here, just as we did before.\n",
    "p_values = reg2.p_values\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "summary_table['p_values'] = p_values\n",
    "summary_table\n",
    "# Here we get the results for our final PD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg2, open('pd_model.sav', 'wb'))\n",
    "# Here we export our model to a 'SAV' file with file name 'pd_model.sav'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD Model Validation (Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-sample validation (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, from the dataframe with inputs for testing, we keep the same variables that we used in our final PD model.\n",
    "inputs_test_with_ref_cat = loan_data_inputs_test.loc[: , ['grade:A',\n",
    "'grade:B',\n",
    "'grade:C',\n",
    "'grade:D',\n",
    "'grade:E',\n",
    "'grade:F',\n",
    "'grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'home_ownership:OWN',\n",
    "'home_ownership:MORTGAGE',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'addr_state:NM_VA',\n",
    "'addr_state:NY',\n",
    "'addr_state:OK_TN_MO_LA_MD_NC',\n",
    "'addr_state:CA',\n",
    "'addr_state:UT_KY_AZ_NJ',\n",
    "'addr_state:AR_MI_PA_OH_MN',\n",
    "'addr_state:RI_MA_DE_SD_IN',\n",
    "'addr_state:GA_WA_OR',\n",
    "'addr_state:WI_MT',\n",
    "'addr_state:TX',\n",
    "'addr_state:IL_CT',\n",
    "'addr_state:KS_SC_CO_VT_AK_MS',\n",
    "'addr_state:WV_NH_WY_DC_ME_ID',\n",
    "'verification_status:Not Verified',\n",
    "'verification_status:Source Verified',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'purpose:credit_card',\n",
    "'purpose:debt_consolidation',\n",
    "'purpose:oth__med__vacation',\n",
    "'purpose:major_purch__car__home_impr',\n",
    "'initial_list_status:f',\n",
    "'initial_list_status:w',\n",
    "'term:36',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'emp_length:1',\n",
    "'emp_length:2-4',\n",
    "'emp_length:5-6',\n",
    "'emp_length:7-9',\n",
    "'emp_length:10',\n",
    "'mths_since_issue_d:<38',\n",
    "'mths_since_issue_d:38-39',\n",
    "'mths_since_issue_d:40-41',\n",
    "'mths_since_issue_d:42-48',\n",
    "'mths_since_issue_d:49-52',\n",
    "'mths_since_issue_d:53-64',\n",
    "'mths_since_issue_d:65-84',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:<9.548',\n",
    "'int_rate:9.548-12.025',\n",
    "'int_rate:12.025-15.74',\n",
    "'int_rate:15.74-20.281',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'mths_since_earliest_cr_line:141-164',\n",
    "'mths_since_earliest_cr_line:165-247',\n",
    "'mths_since_earliest_cr_line:248-270',\n",
    "'mths_since_earliest_cr_line:271-352',\n",
    "'mths_since_earliest_cr_line:>352',\n",
    "'inq_last_6mths:0',\n",
    "'inq_last_6mths:1-2',\n",
    "'inq_last_6mths:3-6',\n",
    "'inq_last_6mths:>6',\n",
    "'acc_now_delinq:0',\n",
    "'acc_now_delinq:>=1',\n",
    "'annual_inc:<20K',\n",
    "'annual_inc:20K-30K',\n",
    "'annual_inc:30K-40K',\n",
    "'annual_inc:40K-50K',\n",
    "'annual_inc:50K-60K',\n",
    "'annual_inc:60K-70K',\n",
    "'annual_inc:70K-80K',\n",
    "'annual_inc:80K-90K',\n",
    "'annual_inc:90K-100K',\n",
    "'annual_inc:100K-120K',\n",
    "'annual_inc:120K-140K',\n",
    "'annual_inc:>140K',\n",
    "'dti:<=1.4',\n",
    "'dti:1.4-3.5',\n",
    "'dti:3.5-7.7',\n",
    "'dti:7.7-10.5',\n",
    "'dti:10.5-16.1',\n",
    "'dti:16.1-20.3',\n",
    "'dti:20.3-21.7',\n",
    "'dti:21.7-22.4',\n",
    "'dti:22.4-35',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:Missing',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_delinq:4-30',\n",
    "'mths_since_last_delinq:31-56',\n",
    "'mths_since_last_delinq:>=57',\n",
    "'mths_since_last_record:Missing',\n",
    "'mths_since_last_record:0-2',\n",
    "'mths_since_last_record:3-20',\n",
    "'mths_since_last_record:21-31',\n",
    "'mths_since_last_record:32-80',\n",
    "'mths_since_last_record:81-86',\n",
    "'mths_since_last_record:>=86',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here, in the list below, we keep the variable names for the reference categories,\n",
    "# only for the variables we used in our final PD model.\n",
    "ref_categories = ['grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'initial_list_status:f',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'inq_last_6mths:>6',\n",
    "'acc_now_delinq:0',\n",
    "'annual_inc:<20K',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_record:0-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = inputs_test_with_ref_cat.drop(ref_categories, axis = 1)\n",
    "inputs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = reg2.model.predict(inputs_test)\n",
    "# Calculates the predicted values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test\n",
    "# This is an array of predicted discrete classess (in this case, 0s and 1s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba = reg2.model.predict_proba(inputs_test)\n",
    "# Calculates the predicted probability values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba\n",
    "# This is an array of arrays of predicted class probabilities for all classes.\n",
    "# In this case, the first value of every sub-array is the probability for the observation to belong to the first class, i.e. 0,\n",
    "# and the second value is the probability for the observation to belong to the first class, i.e. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba[:][:,1]\n",
    "# Here we take all the arrays in the array, and from each array, we take all rows, and only the element with index 1,\n",
    "# that is, the second element.\n",
    "# In other words, we take only the probabilities for being 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba = y_hat_test_proba[: ][: , 1]\n",
    "# We store these probabilities in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba\n",
    "# This variable contains an array of probabilities of being 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_test_temp = loan_data_targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_test_temp.reset_index(drop = True, inplace = True)\n",
    "# We reset the index of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = pd.concat([loan_data_targets_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n",
    "# Concatenates two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.columns = ['loan_data_targets_test', 'y_hat_test_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.index = loan_data_inputs_test.index\n",
    "# Makes the index of one dataframe equal to the index of another dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Area under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 0.9\n",
    "# We create a new column with an indicator,\n",
    "# where every observation that has predicted probability greater than the threshold has a value of 1,\n",
    "# and every observation that has predicted probability lower than the threshold has a value of 0.\n",
    "df_actual_predicted_probs['y_hat_test'] = np.where(df_actual_predicted_probs['y_hat_test_proba'] > tr, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted'])\n",
    "# Creates a cross-table where the actual values are displayed by rows and the predicted values by columns.\n",
    "# This table is known as a Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]\n",
    "# Here we divide each value of the table by the total number of observations,\n",
    "# thus getting percentages, or, rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[0, 0] + (pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[1, 1]\n",
    "# Here we calculate Accuracy of the model, which is the sum of the diagonal rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test_proba'])\n",
    "# Returns the Receiver Operating Characteristic (ROC) Curve from a set of actual values and their predicted probabilities.\n",
    "# As a result, we get three arrays: the false positive rates, the true positive rates, and the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test_proba'])\n",
    "# Here we store each of the three arrays in a separate variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "# We plot the false positive rate along the x-axis and the true positive rate along the y-axis,\n",
    "# thus plotting the ROC curve.\n",
    "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "# We plot a seconary diagonal line, with dashed line style and black color.\n",
    "plt.xlabel('False positive rate')\n",
    "# We name the x-axis \"False positive rate\".\n",
    "plt.ylabel('True positive rate')\n",
    "# We name the x-axis \"True positive rate\".\n",
    "plt.title('ROC curve')\n",
    "# We name the graph \"ROC curve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROC = roc_auc_score(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test_proba'])\n",
    "# Calculates the Area Under the Receiver Operating Characteristic Curve (AUROC)\n",
    "# from a set of actual values and their predicted probabilities.\n",
    "AUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini and Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = df_actual_predicted_probs.sort_values('y_hat_test_proba')\n",
    "# Sorts a dataframe by the values of a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = df_actual_predicted_probs.reset_index()\n",
    "# We reset the index of a dataframe and overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs['Cumulative N Population'] = df_actual_predicted_probs.index + 1\n",
    "# We calculate the cumulative number of all observations.\n",
    "# We use the new index for that. Since indexing in ython starts from 0, we add 1 to each index.\n",
    "df_actual_predicted_probs['Cumulative N Good'] = df_actual_predicted_probs['loan_data_targets_test'].cumsum()\n",
    "# We calculate cumulative number of 'good', which is the cumulative sum of the column with actual observations.\n",
    "df_actual_predicted_probs['Cumulative N Bad'] = df_actual_predicted_probs['Cumulative N Population'] - df_actual_predicted_probs['loan_data_targets_test'].cumsum()\n",
    "# We calculate cumulative number of 'bad', which is\n",
    "# the difference between the cumulative number of all observations and cumulative number of 'good' for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs['Cumulative Perc Population'] = df_actual_predicted_probs['Cumulative N Population'] / (df_actual_predicted_probs.shape[0])\n",
    "# We calculate the cumulative percentage of all observations.\n",
    "df_actual_predicted_probs['Cumulative Perc Good'] = df_actual_predicted_probs['Cumulative N Good'] / df_actual_predicted_probs['loan_data_targets_test'].sum()\n",
    "# We calculate cumulative percentage of 'good'.\n",
    "df_actual_predicted_probs['Cumulative Perc Bad'] = df_actual_predicted_probs['Cumulative N Bad'] / (df_actual_predicted_probs.shape[0] - df_actual_predicted_probs['loan_data_targets_test'].sum())\n",
    "# We calculate the cumulative percentage of 'bad'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot Gini\n",
    "plt.plot(df_actual_predicted_probs['Cumulative Perc Population'], df_actual_predicted_probs['Cumulative Perc Bad'])\n",
    "# We plot the cumulative percentage of all along the x-axis and the cumulative percentage 'good' along the y-axis,\n",
    "# thus plotting the Gini curve.\n",
    "plt.plot(df_actual_predicted_probs['Cumulative Perc Population'], df_actual_predicted_probs['Cumulative Perc Population'], linestyle = '--', color = 'k')\n",
    "# We plot a seconary diagonal line, with dashed line style and black color.\n",
    "plt.xlabel('Cumulative % Population')\n",
    "# We name the x-axis \"Cumulative % Population\".\n",
    "plt.ylabel('Cumulative % Bad')\n",
    "# We name the y-axis \"Cumulative % Bad\".\n",
    "plt.title('Gini')\n",
    "# We name the graph \"Gini\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gini = AUROC * 2 - 1\n",
    "# Here we calculate Gini from AUROC.\n",
    "Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot KS\n",
    "plt.plot(df_actual_predicted_probs['y_hat_test_proba'], df_actual_predicted_probs['Cumulative Perc Bad'], color = 'r')\n",
    "# We plot the predicted (estimated) probabilities along the x-axis and the cumulative percentage 'bad' along the y-axis,\n",
    "# colored in red.\n",
    "plt.plot(df_actual_predicted_probs['y_hat_test_proba'], df_actual_predicted_probs['Cumulative Perc Good'], color = 'b')\n",
    "# We plot the predicted (estimated) probabilities along the x-axis and the cumulative percentage 'good' along the y-axis,\n",
    "# colored in red.\n",
    "plt.xlabel('Estimated Probability for being Good')\n",
    "# We name the x-axis \"Estimated Probability for being Good\".\n",
    "plt.ylabel('Cumulative %')\n",
    "# We name the y-axis \"Cumulative %\".\n",
    "plt.title('Kolmogorov-Smirnov')\n",
    "# We name the graph \"Kolmogorov-Smirnov\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS = max(df_actual_predicted_probs['Cumulative Perc Bad'] - df_actual_predicted_probs['Cumulative Perc Good'])\n",
    "# We calculate KS from the data. It is the maximum of the difference between the cumulative percentage of 'bad'\n",
    "# and the cumulative percentage of 'good'.\n",
    "KS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the PD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating PD of individual accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "# Sets the pandas dataframe options to display all columns/ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_categories = pd.DataFrame(ref_categories, columns = ['Feature name'])\n",
    "# We create a new dataframe with one column. Its values are the values from the 'reference_categories' list.\n",
    "# We name it 'Feature name'.\n",
    "df_ref_categories['Coefficients'] = 0\n",
    "# We create a second column, called 'Coefficients', which contains only 0 values.\n",
    "df_ref_categories['p_values'] = np.nan\n",
    "# We create a third column, called 'p_values', with contains only NaN values.\n",
    "df_ref_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard = pd.concat([summary_table, df_ref_categories])\n",
    "# Concatenates two dataframes.\n",
    "df_scorecard = df_scorecard.reset_index()\n",
    "# We reset the index of a dataframe.\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard['Original feature name'] = df_scorecard['Feature name'].str.split(':').str[0]\n",
    "# We create a new column, called 'Original feature name', which contains the value of the 'Feature name' column,\n",
    "# up to the column symbol.\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = 300\n",
    "max_score = 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard.groupby('Original feature name')['Coefficients'].min()\n",
    "# Groups the data by the values of the 'Original feature name' column.\n",
    "# Aggregates the data in the 'Coefficients' column, calculating their minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].min().sum()\n",
    "# Up to the 'min()' method everything is the same as in te line above.\n",
    "# Then, we aggregate further and sum all the minimum values.\n",
    "min_sum_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_scorecard.groupby('Original feature name')['Coefficients'].max()\n",
    "# Groups the data by the values of the 'Original feature name' column.\n",
    "# Aggregates the data in the 'Coefficients' column, calculating their maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].max().sum()\n",
    "# Up to the 'min()' method everything is the same as in te line above.\n",
    "# Then, we aggregate further and sum all the maximum values.\n",
    "max_sum_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard['Score - Calculation'] = df_scorecard['Coefficients'] * (max_score - min_score) / (max_sum_coef - min_sum_coef)\n",
    "# We multiply the value of the 'Coefficients' column by the ration of the differences between\n",
    "# maximum score and minimum score and maximum sum of coefficients and minimum sum of cefficients.\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard['Score - Calculation'][0] = ((df_scorecard['Coefficients'][0] - min_sum_coef) / (max_sum_coef - min_sum_coef)) * (max_score - min_score) + min_score\n",
    "# We divide the difference of the value of the 'Coefficients' column and the minimum sum of coefficients by\n",
    "# the difference of the maximum sum of coefficients and the minimum sum of coefficients.\n",
    "# Then, we multiply that by the difference between the maximum score and the minimum score.\n",
    "# Then, we add minimum score. \n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard['Score - Preliminary'] = df_scorecard['Score - Calculation'].round()\n",
    "# We round the values of the 'Score - Calculation' column.\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].min().sum()\n",
    "# Groups the data by the values of the 'Original feature name' column.\n",
    "# Aggregates the data in the 'Coefficients' column, calculating their minimum.\n",
    "# Sums all minimum values.\n",
    "min_sum_score_prel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].max().sum()\n",
    "# Groups the data by the values of the 'Original feature name' column.\n",
    "# Aggregates the data in the 'Coefficients' column, calculating their maximum.\n",
    "# Sums all maximum values.\n",
    "max_sum_score_prel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One has to be subtracted from the maximum score for one original variable. Which one? We'll evaluate based on differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard['Difference'] = df_scorecard['Score - Preliminary'] - df_scorecard['Score - Calculation']\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard['Score - Final'] = df_scorecard['Score - Preliminary']\n",
    "df_scorecard['Score - Final'][77] = 16\n",
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Final'].min().sum()\n",
    "# Groups the data by the values of the 'Original feature name' column.\n",
    "# Aggregates the data in the 'Coefficients' column, calculating their minimum.\n",
    "# Sums all minimum values.\n",
    "min_sum_score_prel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Final'].max().sum()\n",
    "# Groups the data by the values of the 'Original feature name' column.\n",
    "# Aggregates the data in the 'Coefficients' column, calculating their maximum.\n",
    "# Sums all maximum values.\n",
    "max_sum_score_prel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caclulating Credit Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat_w_intercept = inputs_test_with_ref_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat_w_intercept.insert(0, 'Intercept', 1)\n",
    "# We insert a column in the dataframe, with an index of 0, that is, in the beginning of the dataframe.\n",
    "# The name of that column is 'Intercept', and its values are 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat_w_intercept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat_w_intercept = inputs_test_with_ref_cat_w_intercept[df_scorecard['Feature name'].values]\n",
    "# Here, from the 'inputs_test_with_ref_cat_w_intercept' dataframe, we keep only the columns with column names,\n",
    "# exactly equal to the row values of the 'Feature name' column from the 'df_scorecard' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat_w_intercept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_scores = df_scorecard['Score - Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_with_ref_cat_w_intercept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_scores = scorecard_scores.values.reshape(102, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = inputs_test_with_ref_cat_w_intercept.dot(scorecard_scores)\n",
    "# Here we multiply the values of each row of the dataframe by the values of each column of the variable,\n",
    "# which is an argument of the 'dot' method, and sum them. It's essentially the sum of the products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Credit Score to PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_coef_from_score = ((y_scores - min_score) / (max_score - min_score)) * (max_sum_coef - min_sum_coef) + min_sum_coef\n",
    "# We divide the difference between the scores and the minimum score by\n",
    "# the difference between the maximum score and the minimum score.\n",
    "# Then, we multiply that by the difference between the maximum sum of coefficients and the minimum sum of coefficients.\n",
    "# Then, we add the minimum sum of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_proba_from_score = np.exp(sum_coef_from_score) / (np.exp(sum_coef_from_score) + 1)\n",
    "# Here we divide an exponent raised to sum of coefficients from score by\n",
    "# an exponent raised to sum of coefficients from score plus one.\n",
    "y_hat_proba_from_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba[0: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs['y_hat_test_proba'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Cut-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the confusion matrix again.\n",
    "#np.where(np.squeeze(np.array(loan_data_targets_test)) == np.where(y_hat_test_proba >= tr, 1, 0), 1, 0).sum() / loan_data_targets_test.shape[0]\n",
    "tr = 0.9\n",
    "df_actual_predicted_probs['y_hat_test'] = np.where(df_actual_predicted_probs['y_hat_test_proba'] > tr, 1, 0)\n",
    "#df_actual_predicted_probs['loan_data_targets_test'] == np.where(df_actual_predicted_probs['y_hat_test_proba'] >= tr, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[0, 0] + (pd.crosstab(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_actual_predicted_probs['loan_data_targets_test'], df_actual_predicted_probs['y_hat_test_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs = pd.concat([pd.DataFrame(thresholds), pd.DataFrame(fpr), pd.DataFrame(tpr)], axis = 1)\n",
    "# We concatenate 3 dataframes along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.columns = ['thresholds', 'fpr', 'tpr']\n",
    "# We name the columns of the dataframe 'thresholds', 'fpr', and 'tpr'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs['thresholds'][0] = 1 - 1 / np.power(10, 16)\n",
    "# Let the first threshold (the value of the thresholds column with index 0) be equal to a number, very close to 1\n",
    "# but smaller than 1, say 1 - 1 / 10 ^ 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs['Score'] = ((np.log(df_cutoffs['thresholds'] / (1 - df_cutoffs['thresholds'])) - min_sum_coef) * ((max_score - min_score) / (max_sum_coef - min_sum_coef)) + min_score).round()\n",
    "# The score corresponsing to each threshold equals:\n",
    "# The the difference between the natural logarithm of the ratio of the threshold and 1 minus the threshold and\n",
    "# the minimum sum of coefficients\n",
    "# multiplied by\n",
    "# the sum of the minimum score and the ratio of the difference between the maximum score and minimum score and \n",
    "# the difference between the maximum sum of coefficients and the minimum sum of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs['Score'][0] = max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function called 'n_approved' which assigns a value of 1 if a predicted probability\n",
    "# is greater than the parameter p, which is a threshold, and a value of 0, if it is not.\n",
    "# Then it sums the column.\n",
    "# Thus, if given any percentage values, the function will return\n",
    "# the number of rows wih estimated probabilites greater than the threshold. \n",
    "def n_approved(p):\n",
    "    return np.where(df_actual_predicted_probs['y_hat_test_proba'] >= p, 1, 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs['N Approved'] = df_cutoffs['thresholds'].apply(n_approved)\n",
    "# Assuming that all credit applications above a given probability of being 'good' will be approved,\n",
    "# when we apply the 'n_approved' function to a threshold, it will return the number of approved applications.\n",
    "# Thus, here we calculate the number of approved appliations for al thresholds.\n",
    "df_cutoffs['N Rejected'] = df_actual_predicted_probs['y_hat_test_proba'].shape[0] - df_cutoffs['N Approved']\n",
    "# Then, we calculate the number of rejected applications for each threshold.\n",
    "# It is the difference between the total number of applications and the approved applications for that threshold.\n",
    "df_cutoffs['Approval Rate'] = df_cutoffs['N Approved'] / df_actual_predicted_probs['y_hat_test_proba'].shape[0]\n",
    "# Approval rate equalts the ratio of the approved applications and all applications.\n",
    "df_cutoffs['Rejection Rate'] = 1 - df_cutoffs['Approval Rate']\n",
    "# Rejection rate equals one minus approval rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.iloc[5000: 6200, ]\n",
    "# Here we display the dataframe with cutoffs form line with index 5000 to line with index 6200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoffs.iloc[1000: 2000, ]\n",
    "# Here we display the dataframe with cutoffs form line with index 1000 to line with index 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_with_ref_cat.to_csv('inputs_train_with_ref_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecard.to_csv('df_scorecard.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
